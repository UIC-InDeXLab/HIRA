{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d191aaa5",
   "metadata": {},
   "source": [
    "# Product Quantization Cluster Size Analysis\n",
    "\n",
    "This notebook analyzes how cluster sizes vary when applying PQ clustering to different data distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f01705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9cb69",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47544f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension: 128, Subvectors: 8, Subvector dim: 16\n",
      "Clusters per subvector: 256\n"
     ]
    }
   ],
   "source": [
    "# PQ parameters\n",
    "n_points = 10000\n",
    "dimension = 128\n",
    "n_subvectors = 8  # Split dimension into subvectors\n",
    "n_clusters = 256  # Number of clusters per subvector (typically 256 for 8-bit codes)\n",
    "\n",
    "# Ensure dimension is divisible by n_subvectors\n",
    "subvector_dim = dimension // n_subvectors\n",
    "print(f\"Dimension: {dimension}, Subvectors: {n_subvectors}, Subvector dim: {subvector_dim}\")\n",
    "print(f\"Clusters per subvector: {n_clusters}\")\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0227103",
   "metadata": {},
   "source": [
    "## Generate Different Data Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47e2ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated 7 distributions\n"
     ]
    }
   ],
   "source": [
    "def generate_distributions(n, d):\n",
    "    \"\"\"Generate various data distributions.\"\"\"\n",
    "    distributions = {}\n",
    "    \n",
    "    # 1. Uniform distribution [0, 1]\n",
    "    distributions['Uniform [0,1]'] = np.random.uniform(0, 1, (n, d))\n",
    "    \n",
    "    # 2. Standard Gaussian\n",
    "    distributions['Gaussian (0,1)'] = np.random.randn(n, d)\n",
    "    \n",
    "    # 3. Wide Gaussian\n",
    "    distributions['Gaussian (0,5)'] = np.random.randn(n, d) * 5\n",
    "    \n",
    "    # 4. Mixture of Gaussians (10 components)\n",
    "    n_mixture = 10\n",
    "    cluster_centers = np.random.randn(n_mixture, d) * 5\n",
    "    cluster_assignments = np.random.randint(0, n_mixture, n)\n",
    "    mixture = cluster_centers[cluster_assignments] + np.random.randn(n, d) * 1.0\n",
    "    distributions['Mixture of Gaussians (10)'] = mixture\n",
    "    \n",
    "    # 5. Sparse data (mostly zeros)\n",
    "    sparse = np.random.randn(n, d) * 0.1\n",
    "    mask = np.random.rand(n, d) > 0.9  # Only 10% non-zero\n",
    "    distributions['Sparse (10% density)'] = sparse * mask\n",
    "    \n",
    "    # 6. Heavy-tailed (Laplace)\n",
    "    distributions['Laplace (0,1)'] = np.random.laplace(0, 1, (n, d))\n",
    "    \n",
    "    # 7. Zipf distribution (power-law)\n",
    "    # Generate Zipf values and map to vectors\n",
    "    zipf_values = np.random.zipf(1.5, (n, d))\n",
    "    # Normalize to reasonable range\n",
    "    zipf_data = (zipf_values - zipf_values.mean()) / (zipf_values.std() + 1e-8)\n",
    "    distributions['Zipf (a=1.5)'] = zipf_data\n",
    "    \n",
    "    return distributions\n",
    "\n",
    "distributions = generate_distributions(n_points, dimension)\n",
    "print(f\"Generated {len(distributions)} distributions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a9be423",
   "metadata": {},
   "source": [
    "## Apply Product Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8d4004",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pq_clustering(data, n_subvectors, n_clusters):\n",
    "    \"\"\"\n",
    "    Apply Product Quantization to data.\n",
    "    \n",
    "    Returns cluster size statistics for each subvector.\n",
    "    \"\"\"\n",
    "    n_samples, dim = data.shape\n",
    "    subvector_dim = dim // n_subvectors\n",
    "    \n",
    "    cluster_size_stats = []\n",
    "    \n",
    "    for i in range(n_subvectors):\n",
    "        # Extract subvector\n",
    "        start_idx = i * subvector_dim\n",
    "        end_idx = (i + 1) * subvector_dim\n",
    "        subvector_data = data[:, start_idx:end_idx]\n",
    "        \n",
    "        # Cluster this subvector\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "        labels = kmeans.fit_predict(subvector_data)\n",
    "        \n",
    "        # Count cluster sizes\n",
    "        cluster_counts = Counter(labels)\n",
    "        sizes = list(cluster_counts.values())\n",
    "        \n",
    "        cluster_size_stats.append({\n",
    "            'subvector': i,\n",
    "            'sizes': sizes,\n",
    "            'mean': np.mean(sizes),\n",
    "            'std': np.std(sizes),\n",
    "            'min': np.min(sizes),\n",
    "            'max': np.max(sizes),\n",
    "            'empty_clusters': n_clusters - len(cluster_counts)\n",
    "        })\n",
    "    \n",
    "    return cluster_size_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b28d731",
   "metadata": {},
   "source": [
    "## Analyze Cluster Sizes for Each Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d47bdba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Uniform [0,1]:\n",
      "--------------------------------------------------\n",
      "  Mean cluster size: 39.06 ± 0.00\n",
      "  Std of cluster sizes: 5.82 ± 0.27\n",
      "  Total empty clusters: 0/2048\n",
      "\n",
      "Gaussian (0,1):\n",
      "--------------------------------------------------\n",
      "  Mean cluster size: 39.06 ± 0.00\n",
      "  Std of cluster sizes: 6.62 ± 0.25\n",
      "  Total empty clusters: 0/2048\n",
      "\n",
      "Gaussian (0,5):\n",
      "--------------------------------------------------\n",
      "  Mean cluster size: 39.06 ± 0.00\n",
      "  Std of cluster sizes: 6.46 ± 0.21\n",
      "  Total empty clusters: 0/2048\n",
      "\n",
      "Mixture of Gaussians (10):\n",
      "--------------------------------------------------\n",
      "  Mean cluster size: 39.06 ± 0.00\n",
      "  Std of cluster sizes: 8.10 ± 0.59\n",
      "  Total empty clusters: 0/2048\n",
      "\n",
      "Sparse (10% density):\n",
      "--------------------------------------------------\n",
      "  Mean cluster size: 39.06 ± 0.00\n",
      "  Std of cluster sizes: 176.97 ± 3.15\n",
      "  Total empty clusters: 0/2048\n",
      "\n",
      "Laplace (0,1):\n",
      "--------------------------------------------------\n",
      "  Mean cluster size: 39.06 ± 0.00\n",
      "  Std of cluster sizes: 12.54 ± 0.35\n",
      "  Total empty clusters: 0/2048\n",
      "\n",
      "Zipf (a=1.5):\n",
      "--------------------------------------------------\n",
      "  Mean cluster size: 39.06 ± 0.00\n",
      "  Std of cluster sizes: 539.47 ± 10.02\n",
      "  Total empty clusters: 0/2048\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "for dist_name, data in distributions.items():\n",
    "    print(f\"\\n{dist_name}:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    stats = apply_pq_clustering(data, n_subvectors, n_clusters)\n",
    "    results[dist_name] = stats\n",
    "    \n",
    "    # Aggregate statistics across all subvectors\n",
    "    all_means = [s['mean'] for s in stats]\n",
    "    all_stds = [s['std'] for s in stats]\n",
    "    total_empty = sum(s['empty_clusters'] for s in stats)\n",
    "    \n",
    "    print(f\"  Mean cluster size: {np.mean(all_means):.2f} ± {np.std(all_means):.2f}\")\n",
    "    print(f\"  Std of cluster sizes: {np.mean(all_stds):.2f} ± {np.std(all_stds):.2f}\")\n",
    "    print(f\"  Total empty clusters: {total_empty}/{n_subvectors * n_clusters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cc4d461",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b6d3992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "SUMMARY: Cluster Size Statistics by Distribution\n",
      "====================================================================================================\n",
      "Distribution              Mean Size    Std Size     Min Size   Max Size   Empty Clusters \n",
      "----------------------------------------------------------------------------------------------------\n",
      "Uniform [0,1]             39.06        5.83         22         62         0/2048         \n",
      "Gaussian (0,1)            39.06        6.63         14         65         0/2048         \n",
      "Gaussian (0,5)            39.06        6.46         12         70         0/2048         \n",
      "Mixture of Gaussians (10) 39.06        8.12         2          76         0/2048         \n",
      "Sparse (10% density)      39.06        176.99       1          2914       0/2048         \n",
      "Laplace (0,1)             39.06        12.55        1          90         0/2048         \n",
      "Zipf (a=1.5)              39.06        539.56       1          8858       0/2048         \n"
     ]
    }
   ],
   "source": [
    "# Create summary table\n",
    "summary_data = []\n",
    "\n",
    "for dist_name, stats in results.items():\n",
    "    all_sizes = []\n",
    "    for subvec_stats in stats:\n",
    "        all_sizes.extend(subvec_stats['sizes'])\n",
    "    \n",
    "    total_empty = sum(s['empty_clusters'] for s in stats)\n",
    "    \n",
    "    summary_data.append({\n",
    "        'Distribution': dist_name,\n",
    "        'Mean Size': f\"{np.mean(all_sizes):.2f}\",\n",
    "        'Std Size': f\"{np.std(all_sizes):.2f}\",\n",
    "        'Min Size': f\"{np.min(all_sizes):.0f}\",\n",
    "        'Max Size': f\"{np.max(all_sizes):.0f}\",\n",
    "        'Empty Clusters': f\"{total_empty}/{n_subvectors * n_clusters}\"\n",
    "    })\n",
    "\n",
    "# Display as formatted table\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SUMMARY: Cluster Size Statistics by Distribution\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Distribution':<25} {'Mean Size':<12} {'Std Size':<12} {'Min Size':<10} {'Max Size':<10} {'Empty Clusters':<15}\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for row in summary_data:\n",
    "    print(f\"{row['Distribution']:<25} {row['Mean Size']:<12} {row['Std Size']:<12} \"\n",
    "          f\"{row['Min Size']:<10} {row['Max Size']:<10} {row['Empty Clusters']:<15}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

"""
Placeholder for sparse attention CUDA kernels.

Future CUDA sparse attention implementations will be exposed here.
"""

# TODO: Implement CUDA kernels for:
# - sparse_attention_cuda
# - gather_scatter_cuda
# - sparse_softmax_cuda
# - fused_attention_cuda

def sparse_attention_kernels_available() -> bool:
    """Check if sparse attention CUDA kernels are available."""
    return False

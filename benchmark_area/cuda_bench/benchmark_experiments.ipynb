{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f35d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from typing import Tuple\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "import triton.testing as tt\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, \"../..\")\n",
    "\n",
    "from hira.index.indexer import CUDAIndexer\n",
    "from hira.index.searcher import CUDASearcher\n",
    "from hira.benchmark_area.utils.data_loader import get_real_data\n",
    "from hira.kernels.triton_wrappers import (\n",
    "    triton_two_level_filter,\n",
    "    triton_three_level_filter_v1,\n",
    ")\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39455f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configs\n",
    "CONFIG = {\n",
    "    \"num_keys_list\": [10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000],\n",
    "    \"branching_factors\": [4, 8, 16, 32, 64],\n",
    "    \"distributions\": [\"real\"],  # , \"uniform\", \"mixture_of_gaussians\", \"zipf\"],\n",
    "    \"dim\": 128,\n",
    "    \"device\": \"cuda\",\n",
    "    \"target_results\": 10,\n",
    "    \"max_iterations\": 1,\n",
    "    \"seed\": 42,\n",
    "    \"real_data_path\": \"../kv_sampling/kv_data/kv_data_Meta-Llama-3-8B-Instruct_layer31_20251219_005742.npz\",\n",
    "    \"output_csv\": \"benchmark_results.csv\",\n",
    "}\n",
    "\n",
    "# Results storage\n",
    "results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d2b8a",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa4cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_all_scores(K, q):\n",
    "    # q_norm = q / torch.norm(q, p=2)\n",
    "    scores = K @ q  # (n,)\n",
    "    return scores\n",
    "\n",
    "\n",
    "def brute_force(\n",
    "    keys: torch.Tensor, query: torch.Tensor, threshold: float\n",
    ") -> torch.Tensor:\n",
    "    # query_norm = query / torch.norm(query, p=2)\n",
    "    scores = torch.matmul(keys, query)\n",
    "    result = (scores >= threshold).nonzero(as_tuple=True)[0]\n",
    "    return result\n",
    "\n",
    "\n",
    "def indexed_search(\n",
    "    indexer: CUDAIndexer,\n",
    "    searcher: CUDASearcher,\n",
    "    query: torch.Tensor,\n",
    "    threshold: float,\n",
    ") -> torch.Tensor:\n",
    "    return searcher.search(query, threshold, indexer)\n",
    "\n",
    "\n",
    "def run_func(func, warmup, runs):\n",
    "    # Warmup\n",
    "    for _ in range(warmup):\n",
    "        func()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    # start = torch.cuda.Event(enable_timing=True)\n",
    "    # end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    # times_ms = []\n",
    "\n",
    "    # torch.cuda.synchronize()\n",
    "\n",
    "    # for _ in range(runs):\n",
    "    #     start.record()\n",
    "    #     for _ in range(inner):\n",
    "    #         func()\n",
    "    #     end.record()\n",
    "    #     torch.cuda.synchronize()\n",
    "    #     times_ms.append(start.elapsed_time(end) / inner)  # milliseconds\n",
    "\n",
    "    # times_ms = np.array(times_ms)\n",
    "    # return times_ms.mean()\n",
    "    ms = tt.do_bench(func, warmup=warmup, rep=runs)\n",
    "    return ms\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def run_benchmark(\n",
    "    keys: torch.Tensor,\n",
    "    branching_factor: int,\n",
    "    dim: int,\n",
    "    max_iterations: int,\n",
    "    target_results: int,\n",
    "    warmup: int,\n",
    "    num_runs: int,\n",
    "    outer: int,\n",
    ") -> Tuple[float, float, float, float]:\n",
    "    keys = keys.to(\"cuda\")\n",
    "\n",
    "    # build indexes\n",
    "    two_level_index = CUDAIndexer(\n",
    "        depth=CUDAIndexer.DEPTH.TWO_LEVELS,\n",
    "        branching_factor=branching_factor,\n",
    "        # branching_factor=8,\n",
    "        max_iterations=max_iterations,\n",
    "    ).build(keys)\n",
    "    three_level_index = CUDAIndexer(\n",
    "        depth=CUDAIndexer.DEPTH.THREE_LEVELS,\n",
    "        branching_factor=branching_factor,\n",
    "        # branching_factor=4,\n",
    "        max_iterations=max_iterations,\n",
    "    ).build(keys)\n",
    "    searcher_two_levels = CUDASearcher(block_c=branching_factor)\n",
    "    searcher_three_levels = CUDASearcher(block_c=branching_factor)\n",
    "\n",
    "    # Create query and find threshold (only once)\n",
    "    query = torch.randn(dim).to(\"cuda\")\n",
    "    query = query / torch.norm(query, p=2)\n",
    "    all_scores = torch.matmul(keys, query)\n",
    "    sorted_scores, _ = torch.sort(all_scores, descending=True)\n",
    "    threshold = sorted_scores[min(target_results, len(sorted_scores) - 1)].item()\n",
    "\n",
    "    benchmarks = [\n",
    "        (\"all_scores\", lambda: calc_all_scores(keys, query)),\n",
    "        (\"bf\", lambda: brute_force(keys, query, threshold)),\n",
    "        (\n",
    "            \"two\",\n",
    "            lambda: indexed_search(\n",
    "                two_level_index,\n",
    "                searcher_two_levels,\n",
    "                query,\n",
    "                threshold,\n",
    "            ),\n",
    "        ),\n",
    "        (\n",
    "            \"three\",\n",
    "            lambda: indexed_search(\n",
    "                three_level_index,\n",
    "                searcher_three_levels,\n",
    "                query,\n",
    "                threshold,\n",
    "            ),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    results = {\n",
    "        \"all_scores\": 0.0,\n",
    "        \"bf\": 0.0,\n",
    "        \"two\": 0.0,\n",
    "        \"three\": 0.0,\n",
    "    }\n",
    "\n",
    "    for _ in range(outer):\n",
    "        random.shuffle(benchmarks)\n",
    "\n",
    "        for name, fn in benchmarks:\n",
    "            results[name] += run_func(fn, warmup, num_runs)\n",
    "\n",
    "    return (\n",
    "        results[\"all_scores\"] / outer,\n",
    "        results[\"bf\"] / outer,\n",
    "        results[\"two\"] / outer,\n",
    "        results[\"three\"] / outer,\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"Search functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e118e465",
   "metadata": {},
   "source": [
    "### Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9c3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = []\n",
    "# output_csv = Path(CONFIG[\"output_csv\"])\n",
    "\n",
    "# for num_keys in CONFIG[\"num_keys_list\"]:\n",
    "#     print(f\"Running benchmarks for {num_keys} keys...\")\n",
    "\n",
    "#     keys = get_real_data(\n",
    "#         num_keys,\n",
    "#         CONFIG[\"dim\"],\n",
    "#         seed=CONFIG[\"seed\"],\n",
    "#         real_data_path=CONFIG[\"real_data_path\"],\n",
    "#     )\n",
    "\n",
    "#     for branching_factor in CONFIG[\"branching_factors\"]:\n",
    "#         print(f\"  Branching Factor: {branching_factor}\")\n",
    "\n",
    "#         all_scores_mean, bf_mean, two_level_mean, three_level_mean = run_benchmark(\n",
    "#             keys=keys,\n",
    "#             dim=CONFIG[\"dim\"],\n",
    "#             max_iterations=CONFIG[\"max_iterations\"],\n",
    "#             target_results=CONFIG[\"target_results\"],\n",
    "#             branching_factor=branching_factor,\n",
    "#             warmup=10,\n",
    "#             num_runs=100,\n",
    "#             outer=20,\n",
    "#         )\n",
    "\n",
    "#         result = {\n",
    "#             \"num_keys\": num_keys,\n",
    "#             \"all_scores_mean_ms\": all_scores_mean,\n",
    "#             \"brute_force_mean_ms\": bf_mean,\n",
    "#             \"two_level_mean_ms\": two_level_mean,\n",
    "#             \"three_level_mean_ms\": three_level_mean,\n",
    "#             \"branching_factor\": branching_factor,\n",
    "#         }\n",
    "\n",
    "#         results.append(result)\n",
    "\n",
    "#         # Save intermediate results to CSV after each experiment\n",
    "#         pd.DataFrame(results).to_csv(output_csv, index=False)\n",
    "\n",
    "# # Convert to DataFrame\n",
    "# df_results = pd.DataFrame(results)\n",
    "# print(f\"\\nResults saved to: {output_csv.absolute()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fb2774",
   "metadata": {},
   "source": [
    "#### Triton Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ef60b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_ones = [f\"two_{bf}\" for bf in CONFIG[\"branching_factors\"]]\n",
    "three_ones = [f\"three_{bf}\" for bf in CONFIG[\"branching_factors\"]]\n",
    "\n",
    "# line_vals = [\"all_scores\", \"bf\"] + two_ones + three_ones\n",
    "line_vals = two_ones + three_ones\n",
    "\n",
    "WARMUP = 10\n",
    "RUNS = 100\n",
    "\n",
    "\n",
    "@tt.perf_report(\n",
    "    tt.Benchmark(\n",
    "        x_names=[\"n\"],\n",
    "        x_vals=[10000, 20000, 40000, 60000, 80000, 90000],\n",
    "        line_arg=\"provider\",\n",
    "        line_vals=line_vals,\n",
    "        line_names=line_vals,\n",
    "        ylabel=\"Âµs\",\n",
    "        plot_name=f\"triton_benchmarking\",\n",
    "        args={},\n",
    "    )\n",
    ")\n",
    "def triton_benchmark(n, provider):\n",
    "    # start\n",
    "    if provider.startswith(\"two_\"):\n",
    "        branching_factor = int(provider.split(\"_\")[1])\n",
    "        provider = \"two\"\n",
    "    elif provider.startswith(\"three_\"):\n",
    "        branching_factor = int(provider.split(\"_\")[1])\n",
    "        provider = \"three\"\n",
    "    # end\n",
    "\n",
    "    keys = get_real_data(\n",
    "        n,\n",
    "        CONFIG[\"dim\"],\n",
    "        seed=CONFIG[\"seed\"],\n",
    "        real_data_path=CONFIG[\"real_data_path\"],\n",
    "    )\n",
    "\n",
    "    keys = keys.to(\"cuda\")\n",
    "\n",
    "    # build indexes\n",
    "    two_level_index = CUDAIndexer(\n",
    "        depth=CUDAIndexer.DEPTH.TWO_LEVELS,\n",
    "        branching_factor=branching_factor,\n",
    "        # branching_factor=8,\n",
    "        max_iterations=1,\n",
    "    ).build(keys)\n",
    "    three_level_index = CUDAIndexer(\n",
    "        depth=CUDAIndexer.DEPTH.THREE_LEVELS,\n",
    "        branching_factor=branching_factor,\n",
    "        # branching_factor=4,\n",
    "        max_iterations=1,\n",
    "    ).build(keys)\n",
    "    searcher_two_levels = CUDASearcher(block_c=branching_factor)\n",
    "    searcher_three_levels = CUDASearcher(block_c=branching_factor)\n",
    "\n",
    "    # Create query and find threshold (only once)\n",
    "    query = torch.randn(CONFIG[\"dim\"]).to(\"cuda\")\n",
    "    query = query / torch.norm(query, p=2)\n",
    "    all_scores = torch.matmul(keys, query)\n",
    "    sorted_scores, _ = torch.sort(all_scores, descending=True)\n",
    "    threshold = sorted_scores[\n",
    "        min(CONFIG[\"target_results\"], len(sorted_scores) - 1)\n",
    "    ].item()\n",
    "\n",
    "    benchmarks = {\n",
    "        \"all_scores\": lambda: calc_all_scores(keys, query),\n",
    "        \"bf\": lambda: brute_force(keys, query, threshold),\n",
    "        \"two\": lambda: indexed_search(\n",
    "            two_level_index,\n",
    "            searcher_two_levels,\n",
    "            query,\n",
    "            threshold,\n",
    "        ),\n",
    "        \"three\": lambda: indexed_search(\n",
    "            three_level_index,\n",
    "            searcher_three_levels,\n",
    "            query,\n",
    "            threshold,\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    func = benchmarks[provider]\n",
    "\n",
    "    for _ in range(WARMUP):\n",
    "        func()\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "    ms = tt.do_bench(func, warmup=WARMUP, rep=RUNS)\n",
    "\n",
    "    return ms * 1e3\n",
    "\n",
    "\n",
    "triton_benchmark.run(print_data=True, show_plots=True, save_path=\"./reports\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
